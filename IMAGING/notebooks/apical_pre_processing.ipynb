{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook for pre-processing apical image stack.\n",
    "# --- UNDER DEVELOPMENT ---\n",
    "Assumes folder directory structure:\n",
    "<pre><code>  IMAGING\n",
    "    image_stacks\n",
    "    notebooks\n",
    "    results\n",
    "</code></pre>\n",
    "Execute the code sequentially, one block at a time, using &lt;shift-return&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "from skimage.transform import hough_circle, hough_circle_peaks, resize\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle, circle_perimeter\n",
    "from skimage.restoration import denoise_bilateral, denoise_wavelet\n",
    "from skimage import filters\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipyfilechooser import FileChooser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_stack = \"../image_stacks/Mistgcamp-3_0003.tif\"\n",
    "#image_stack = \"../image_stacks/MOVEMENT.tif\"\n",
    "image_stack = \"../image_stacks/Movement2.tif\"\n",
    "##image_stack = \"../image_stacks/modestmovement.tif\"\n",
    "#image_stack = \"../image_stacks/lessmovement3.tif\"\n",
    "image_bits = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up table for image plot color\n",
    "#   e.g. coolwarm, jet, plasma, gray\n",
    "lut = mpl.cm.gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a082910f2e4393b4ac77879c5698e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "# Load picture\n",
    "images = io.imread(image_stack)\n",
    "images = np.float32(images/(2.0**image_bits))\n",
    "for i in images:\n",
    "  for l in range(i.shape[0] - 1): # moving average over every two lines\n",
    "    i[l] = (i[l] + i[l+1]) / 2.0\n",
    "\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "plt.imshow(images[0], norm=None, cmap=lut.name)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37a98d2e946451080e0298c63784f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='image gain', max=5.0, min=1.0), IntRangeSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "@interact(\n",
    "  gn=widgets.FloatSlider(description='image gain',min=1.0, max=5.0, step=0.1, value=1.0),\n",
    "  sr=widgets.IntRangeSlider(description='stack range',min=0, max=300, step=1, value=[0,5]), \n",
    "  bs=widgets.FloatSlider(description='BILATERAL sigma',min=0.0, max=4.0, step=0.1, value=1.0), \n",
    "  cs=widgets.FloatSlider(description='CANNY sigma',min=1.0, max=4.0, step=0.1, value=1.8), \n",
    "  ct=widgets.IntRangeSlider(description='threshold',min=0, max=100, step=1, value=[9,22]),\n",
    "  hr=widgets.IntRangeSlider(description='HOUGH radii',min=3, max=25, step=1, value=[10,16]),\n",
    "  hd=widgets.IntSlider(description='distance',min=5, max=50, step=1, value=10),\n",
    "  hp=widgets.IntSlider(description='peaks',min=50, max=500, step=10, value=270),\n",
    "  ht=widgets.FloatSlider(description='threshold',min=0.0, max=1.0, step=0.01, value=0.12),\n",
    "  cr=widgets.FloatSlider(description='circle ratio',min=1.0, max=2.0, step=0.01, value=1.2))\n",
    "\n",
    "def f(gn, sr, bs, cs, ct, hr, hd, hp, ht, cr):\n",
    "  A00 = gn*np.mean(images[sr[0]:sr[1]], axis=0) # the static images\n",
    "  A0 = A00 / np.amax(A00) # normalize\n",
    "\n",
    "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(8,8))\n",
    "  imageA = color.gray2rgb(np.uint8(255.0*A0))\n",
    "    \n",
    "  # identify nuclei (circles)   \n",
    "  #A = filters.gaussian(A0, sigma=gs) # noise filter\n",
    "  #A = denoise_wavelet(A0, wavelet_levels=7, multichannel=False, rescale_sigma=False)\n",
    "  A = denoise_bilateral(A0, sigma_spatial=bs)\n",
    "  Auint8 = np.uint8(255.0*A)\n",
    "  edges = canny(Auint8, sigma=cs, low_threshold=ct[0], high_threshold=ct[1])\n",
    "  hough_radii = np.arange(hr[0], hr[1], 1) # the range of radii to use in search\n",
    "  hough_res = hough_circle(edges, hough_radii) # look for circles\n",
    "  accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=hd, \n",
    "                                           min_ydistance=hd, total_num_peaks=hp, \n",
    "                                           threshold=ht, normalize=False)\n",
    "\n",
    "  # remove false positives (bright disks with dark perimeter)\n",
    "  pix = [] # as an empty list (for the remaining center pixels)\n",
    "  for center_y, center_x, radius in zip(cy, cx, radii):\n",
    "    c = circle(center_y, center_x, radius, shape=A0.shape) # central disk\n",
    "    cp = circle_perimeter(center_y, center_x, radius+1, shape=A0.shape) # perimeter ring\n",
    "    if (np.mean(imageA[cp]) / np.mean(imageA[c])) > cr:\n",
    "      pix.append((center_x, center_y)) # dark disks with bright perimeter are OK\n",
    "\n",
    "  # remove duplicates (close center pixels)\n",
    "  pix = np.array(pix) # as a numpy array\n",
    "  tree = cKDTree(pix) # for pairwise distance query\n",
    "  rows_to_fuse = list(tree.query_pairs(r=8.0))\n",
    "  p = np.ones(pix.shape[0])           # array of \"keep\" flags\n",
    "  p[np.array(rows_to_fuse)[:,0]] = 0  # flag the first of all duplicate pairs for deletion\n",
    "  pixx = pix[p.astype(bool)]          # the remaining center pixels \n",
    "\n",
    "  # draw nuclei centre pixels\n",
    "  for i in pixx:\n",
    "    #imageA[i[1], i[0]] = (255,0,0)\n",
    "    imageA[circle(i[1], i[0], 1.1, shape=A0.shape)] = (255,0,0)\n",
    "  \n",
    "  ax.imshow(imageA, norm=None)\n",
    "  plt.show()    \n",
    "  return(str(pixx.shape[0]) + \" nuclei identified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 - 27 nuclei identified\n",
      "4 - 28 nuclei identified\n",
      "5 - 29 nuclei identified\n",
      "6 - 35 nuclei identified\n",
      "7 - 24 nuclei identified\n",
      "8 - 24 nuclei identified\n",
      "9 - 26 nuclei identified\n",
      "10 - 21 nuclei identified\n",
      "11 - 24 nuclei identified\n",
      "12 - 28 nuclei identified\n",
      "13 - 23 nuclei identified\n",
      "14 - 26 nuclei identified\n",
      "15 - 25 nuclei identified\n",
      "16 - 29 nuclei identified\n",
      "17 - 29 nuclei identified\n",
      "18 - 25 nuclei identified\n",
      "19 - 27 nuclei identified\n",
      "20 - 24 nuclei identified\n",
      "21 - 25 nuclei identified\n",
      "22 - 25 nuclei identified\n",
      "23 - 22 nuclei identified\n",
      "24 - 24 nuclei identified\n",
      "25 - 25 nuclei identified\n",
      "26 - 22 nuclei identified\n",
      "27 - 23 nuclei identified\n",
      "28 - 28 nuclei identified\n",
      "29 - 24 nuclei identified\n",
      "30 - 25 nuclei identified\n",
      "31 - 27 nuclei identified\n",
      "32 - 28 nuclei identified\n",
      "33 - 26 nuclei identified\n",
      "34 - 26 nuclei identified\n",
      "35 - 26 nuclei identified\n",
      "36 - 26 nuclei identified\n",
      "37 - 24 nuclei identified\n",
      "38 - 22 nuclei identified\n",
      "39 - 28 nuclei identified\n",
      "40 - 32 nuclei identified\n",
      "41 - 29 nuclei identified\n",
      "42 - 34 nuclei identified\n",
      "43 - 27 nuclei identified\n",
      "44 - 30 nuclei identified\n",
      "45 - 31 nuclei identified\n",
      "46 - 27 nuclei identified\n",
      "47 - 26 nuclei identified\n",
      "48 - 26 nuclei identified\n",
      "49 - 29 nuclei identified\n",
      "50 - 20 nuclei identified\n",
      "51 - 23 nuclei identified\n",
      "52 - 26 nuclei identified\n",
      "53 - 26 nuclei identified\n",
      "54 - 20 nuclei identified\n",
      "55 - 23 nuclei identified\n",
      "56 - 25 nuclei identified\n",
      "57 - 24 nuclei identified\n",
      "58 - 25 nuclei identified\n",
      "59 - 24 nuclei identified\n",
      "60 - 24 nuclei identified\n",
      "61 - 23 nuclei identified\n",
      "62 - 22 nuclei identified\n",
      "63 - 20 nuclei identified\n",
      "64 - 22 nuclei identified\n",
      "65 - 24 nuclei identified\n",
      "66 - 28 nuclei identified\n",
      "67 - 21 nuclei identified\n",
      "68 - 26 nuclei identified\n",
      "69 - 29 nuclei identified\n",
      "70 - 28 nuclei identified\n",
      "71 - 25 nuclei identified\n",
      "72 - 27 nuclei identified\n",
      "73 - 24 nuclei identified\n",
      "74 - 25 nuclei identified\n",
      "75 - 28 nuclei identified\n",
      "76 - 26 nuclei identified\n",
      "77 - 27 nuclei identified\n",
      "78 - 30 nuclei identified\n",
      "79 - 27 nuclei identified\n",
      "80 - 20 nuclei identified\n",
      "81 - 25 nuclei identified\n",
      "82 - 23 nuclei identified\n",
      "83 - 25 nuclei identified\n",
      "84 - 23 nuclei identified\n",
      "85 - 22 nuclei identified\n",
      "86 - 29 nuclei identified\n",
      "87 - 28 nuclei identified\n",
      "88 - 28 nuclei identified\n",
      "89 - 29 nuclei identified\n",
      "90 - 27 nuclei identified\n",
      "91 - 22 nuclei identified\n",
      "92 - 25 nuclei identified\n",
      "93 - 26 nuclei identified\n",
      "94 - 22 nuclei identified\n",
      "95 - 17 nuclei identified\n",
      "96 - 22 nuclei identified\n",
      "97 - 24 nuclei identified\n",
      "98 - 26 nuclei identified\n",
      "99 - 27 nuclei identified\n",
      "100 - 27 nuclei identified\n",
      "101 - 24 nuclei identified\n",
      "102 - 21 nuclei identified\n",
      "103 - 26 nuclei identified\n",
      "104 - 26 nuclei identified\n",
      "105 - 27 nuclei identified\n",
      "106 - 24 nuclei identified\n",
      "107 - 27 nuclei identified\n",
      "108 - 24 nuclei identified\n",
      "109 - 23 nuclei identified\n",
      "110 - 24 nuclei identified\n",
      "111 - 22 nuclei identified\n",
      "112 - 25 nuclei identified\n",
      "113 - 23 nuclei identified\n",
      "114 - 24 nuclei identified\n",
      "115 - 24 nuclei identified\n",
      "116 - 25 nuclei identified\n",
      "117 - 26 nuclei identified\n",
      "118 - 25 nuclei identified\n",
      "119 - 28 nuclei identified\n",
      "120 - 25 nuclei identified\n",
      "121 - 26 nuclei identified\n",
      "122 - 27 nuclei identified\n",
      "123 - 23 nuclei identified\n",
      "124 - 28 nuclei identified\n",
      "125 - 27 nuclei identified\n",
      "126 - 27 nuclei identified\n",
      "127 - 24 nuclei identified\n",
      "128 - 21 nuclei identified\n",
      "129 - 25 nuclei identified\n",
      "130 - 23 nuclei identified\n",
      "131 - 24 nuclei identified\n",
      "132 - 23 nuclei identified\n",
      "133 - 26 nuclei identified\n",
      "134 - 28 nuclei identified\n",
      "135 - 25 nuclei identified\n",
      "136 - 23 nuclei identified\n",
      "137 - 24 nuclei identified\n",
      "138 - 29 nuclei identified\n",
      "139 - 26 nuclei identified\n",
      "140 - 24 nuclei identified\n",
      "141 - 23 nuclei identified\n",
      "142 - 21 nuclei identified\n",
      "143 - 27 nuclei identified\n",
      "144 - 28 nuclei identified\n",
      "145 - 26 nuclei identified\n",
      "146 - 29 nuclei identified\n",
      "147 - 29 nuclei identified\n",
      "148 - 30 nuclei identified\n",
      "149 - 24 nuclei identified\n",
      "150 - 24 nuclei identified\n",
      "151 - 26 nuclei identified\n",
      "152 - 24 nuclei identified\n",
      "153 - 29 nuclei identified\n",
      "154 - 30 nuclei identified\n",
      "155 - 26 nuclei identified\n",
      "156 - 31 nuclei identified\n",
      "157 - 27 nuclei identified\n",
      "158 - 27 nuclei identified\n",
      "159 - 24 nuclei identified\n",
      "160 - 28 nuclei identified\n",
      "161 - 30 nuclei identified\n",
      "162 - 28 nuclei identified\n",
      "163 - 29 nuclei identified\n",
      "164 - 37 nuclei identified\n",
      "165 - 27 nuclei identified\n",
      "166 - 29 nuclei identified\n",
      "167 - 29 nuclei identified\n",
      "168 - 29 nuclei identified\n",
      "169 - 32 nuclei identified\n",
      "170 - 31 nuclei identified\n",
      "171 - 30 nuclei identified\n",
      "172 - 30 nuclei identified\n",
      "173 - 24 nuclei identified\n",
      "174 - 27 nuclei identified\n",
      "175 - 21 nuclei identified\n",
      "176 - 26 nuclei identified\n",
      "177 - 23 nuclei identified\n",
      "178 - 23 nuclei identified\n",
      "179 - 23 nuclei identified\n",
      "180 - 20 nuclei identified\n",
      "181 - 24 nuclei identified\n",
      "182 - 25 nuclei identified\n",
      "183 - 27 nuclei identified\n",
      "184 - 27 nuclei identified\n",
      "185 - 27 nuclei identified\n",
      "186 - 24 nuclei identified\n",
      "187 - 32 nuclei identified\n",
      "188 - 31 nuclei identified\n",
      "189 - 25 nuclei identified\n",
      "190 - 35 nuclei identified\n",
      "191 - 28 nuclei identified\n",
      "192 - 25 nuclei identified\n",
      "193 - 22 nuclei identified\n",
      "194 - 23 nuclei identified\n",
      "195 - 25 nuclei identified\n",
      "196 - 25 nuclei identified\n",
      "197 - 30 nuclei identified\n",
      "198 - 31 nuclei identified\n",
      "199 - 29 nuclei identified\n",
      "200 - 28 nuclei identified\n",
      "201 - 24 nuclei identified\n",
      "202 - 27 nuclei identified\n",
      "203 - 26 nuclei identified\n",
      "204 - 31 nuclei identified\n",
      "205 - 26 nuclei identified\n",
      "206 - 29 nuclei identified\n",
      "207 - 32 nuclei identified\n",
      "208 - 28 nuclei identified\n",
      "209 - 30 nuclei identified\n",
      "210 - 30 nuclei identified\n",
      "211 - 26 nuclei identified\n",
      "212 - 24 nuclei identified\n",
      "213 - 33 nuclei identified\n",
      "214 - 30 nuclei identified\n",
      "215 - 30 nuclei identified\n",
      "216 - 26 nuclei identified\n",
      "217 - 28 nuclei identified\n",
      "218 - 28 nuclei identified\n",
      "219 - 25 nuclei identified\n",
      "220 - 31 nuclei identified\n",
      "221 - 27 nuclei identified\n",
      "222 - 27 nuclei identified\n",
      "223 - 26 nuclei identified\n",
      "224 - 26 nuclei identified\n",
      "225 - 25 nuclei identified\n",
      "226 - 30 nuclei identified\n",
      "227 - 34 nuclei identified\n",
      "228 - 33 nuclei identified\n",
      "229 - 33 nuclei identified\n",
      "230 - 29 nuclei identified\n",
      "231 - 32 nuclei identified\n",
      "232 - 32 nuclei identified\n",
      "233 - 31 nuclei identified\n",
      "234 - 33 nuclei identified\n",
      "235 - 32 nuclei identified\n",
      "236 - 34 nuclei identified\n",
      "237 - 33 nuclei identified\n",
      "238 - 28 nuclei identified\n",
      "239 - 31 nuclei identified\n",
      "240 - 28 nuclei identified\n",
      "241 - 26 nuclei identified\n",
      "242 - 25 nuclei identified\n",
      "243 - 25 nuclei identified\n",
      "244 - 27 nuclei identified\n",
      "245 - 25 nuclei identified\n",
      "246 - 23 nuclei identified\n",
      "247 - 23 nuclei identified\n",
      "248 - 25 nuclei identified\n",
      "249 - 29 nuclei identified\n",
      "250 - 28 nuclei identified\n",
      "251 - 28 nuclei identified\n",
      "252 - 23 nuclei identified\n",
      "253 - 26 nuclei identified\n",
      "254 - 25 nuclei identified\n",
      "255 - 28 nuclei identified\n",
      "256 - 34 nuclei identified\n",
      "257 - 33 nuclei identified\n",
      "258 - 29 nuclei identified\n",
      "259 - 27 nuclei identified\n",
      "260 - 29 nuclei identified\n",
      "261 - 34 nuclei identified\n",
      "262 - 30 nuclei identified\n",
      "263 - 30 nuclei identified\n",
      "264 - 26 nuclei identified\n",
      "265 - 35 nuclei identified\n",
      "266 - 35 nuclei identified\n",
      "267 - 27 nuclei identified\n",
      "268 - 30 nuclei identified\n",
      "269 - 38 nuclei identified\n",
      "270 - 27 nuclei identified\n",
      "271 - 26 nuclei identified\n",
      "272 - 29 nuclei identified\n",
      "273 - 27 nuclei identified\n",
      "274 - 25 nuclei identified\n",
      "275 - 29 nuclei identified\n",
      "276 - 27 nuclei identified\n",
      "277 - 28 nuclei identified\n",
      "278 - 33 nuclei identified\n",
      "279 - 32 nuclei identified\n",
      "280 - 28 nuclei identified\n",
      "281 - 33 nuclei identified\n",
      "282 - 31 nuclei identified\n",
      "283 - 31 nuclei identified\n",
      "284 - 32 nuclei identified\n",
      "285 - 30 nuclei identified\n",
      "286 - 27 nuclei identified\n",
      "287 - 32 nuclei identified\n",
      "288 - 31 nuclei identified\n",
      "289 - 30 nuclei identified\n",
      "290 - 29 nuclei identified\n",
      "291 - 26 nuclei identified\n",
      "292 - 28 nuclei identified\n",
      "293 - 30 nuclei identified\n",
      "294 - 29 nuclei identified\n",
      "295 - 29 nuclei identified\n",
      "296 - 29 nuclei identified\n",
      "297 - 28 nuclei identified\n",
      "298 - 31 nuclei identified\n",
      "299 - 32 nuclei identified\n",
      "300 - 34 nuclei identified\n",
      "301 - 30 nuclei identified\n",
      "302 - 30 nuclei identified\n",
      "303 - 30 nuclei identified\n",
      "304 - 30 nuclei identified\n",
      "305 - 34 nuclei identified\n",
      "306 - 29 nuclei identified\n",
      "307 - 35 nuclei identified\n",
      "308 - 33 nuclei identified\n",
      "309 - 31 nuclei identified\n",
      "310 - 32 nuclei identified\n",
      "311 - 33 nuclei identified\n",
      "312 - 33 nuclei identified\n",
      "313 - 33 nuclei identified\n",
      "314 - 33 nuclei identified\n",
      "315 - 32 nuclei identified\n",
      "316 - 27 nuclei identified\n",
      "317 - 29 nuclei identified\n",
      "318 - 34 nuclei identified\n",
      "319 - 31 nuclei identified\n",
      "320 - 34 nuclei identified\n",
      "321 - 33 nuclei identified\n",
      "322 - 35 nuclei identified\n",
      "323 - 37 nuclei identified\n",
      "324 - 31 nuclei identified\n",
      "325 - 33 nuclei identified\n",
      "326 - 37 nuclei identified\n",
      "327 - 32 nuclei identified\n",
      "328 - 33 nuclei identified\n",
      "329 - 32 nuclei identified\n",
      "330 - 31 nuclei identified\n",
      "331 - 27 nuclei identified\n",
      "332 - 30 nuclei identified\n",
      "333 - 28 nuclei identified\n",
      "334 - 29 nuclei identified\n",
      "335 - 33 nuclei identified\n",
      "336 - 28 nuclei identified\n",
      "337 - 31 nuclei identified\n",
      "338 - 32 nuclei identified\n",
      "339 - 37 nuclei identified\n",
      "340 - 36 nuclei identified\n",
      "341 - 27 nuclei identified\n",
      "342 - 28 nuclei identified\n",
      "343 - 32 nuclei identified\n",
      "344 - 25 nuclei identified\n",
      "345 - 28 nuclei identified\n",
      "346 - 29 nuclei identified\n",
      "347 - 31 nuclei identified\n",
      "348 - 36 nuclei identified\n",
      "349 - 33 nuclei identified\n",
      "350 - 37 nuclei identified\n",
      "351 - 34 nuclei identified\n",
      "352 - 33 nuclei identified\n",
      "353 - 37 nuclei identified\n",
      "354 - 33 nuclei identified\n",
      "355 - 29 nuclei identified\n",
      "356 - 25 nuclei identified\n",
      "357 - 27 nuclei identified\n",
      "358 - 35 nuclei identified\n",
      "359 - 30 nuclei identified\n",
      "360 - 29 nuclei identified\n",
      "361 - 28 nuclei identified\n",
      "362 - 20 nuclei identified\n",
      "363 - 24 nuclei identified\n",
      "364 - 26 nuclei identified\n",
      "365 - 24 nuclei identified\n",
      "366 - 28 nuclei identified\n",
      "367 - 27 nuclei identified\n",
      "368 - 25 nuclei identified\n",
      "369 - 27 nuclei identified\n",
      "370 - 27 nuclei identified\n",
      "371 - 26 nuclei identified\n",
      "372 - 30 nuclei identified\n",
      "373 - 31 nuclei identified\n",
      "374 - 24 nuclei identified\n",
      "375 - 25 nuclei identified\n",
      "376 - 23 nuclei identified\n",
      "377 - 25 nuclei identified\n",
      "378 - 30 nuclei identified\n",
      "379 - 32 nuclei identified\n",
      "380 - 26 nuclei identified\n",
      "381 - 28 nuclei identified\n",
      "382 - 31 nuclei identified\n",
      "383 - 28 nuclei identified\n",
      "384 - 30 nuclei identified\n",
      "385 - 28 nuclei identified\n",
      "386 - 24 nuclei identified\n",
      "387 - 26 nuclei identified\n",
      "388 - 27 nuclei identified\n",
      "389 - 24 nuclei identified\n",
      "390 - 30 nuclei identified\n",
      "391 - 29 nuclei identified\n",
      "392 - 28 nuclei identified\n",
      "393 - 30 nuclei identified\n",
      "394 - 30 nuclei identified\n",
      "395 - 31 nuclei identified\n",
      "396 - 27 nuclei identified\n",
      "397 - 27 nuclei identified\n",
      "398 - 29 nuclei identified\n",
      "399 - 24 nuclei identified\n",
      "400 - 28 nuclei identified\n",
      "401 - 28 nuclei identified\n",
      "402 - 24 nuclei identified\n",
      "403 - 30 nuclei identified\n",
      "404 - 23 nuclei identified\n",
      "405 - 27 nuclei identified\n",
      "406 - 26 nuclei identified\n",
      "407 - 27 nuclei identified\n",
      "408 - 29 nuclei identified\n",
      "409 - 28 nuclei identified\n",
      "410 - 22 nuclei identified\n",
      "411 - 26 nuclei identified\n",
      "412 - 27 nuclei identified\n",
      "413 - 31 nuclei identified\n",
      "414 - 27 nuclei identified\n",
      "415 - 25 nuclei identified\n",
      "416 - 20 nuclei identified\n",
      "417 - 24 nuclei identified\n",
      "418 - 27 nuclei identified\n",
      "419 - 25 nuclei identified\n",
      "420 - 29 nuclei identified\n",
      "421 - 25 nuclei identified\n",
      "422 - 28 nuclei identified\n",
      "423 - 25 nuclei identified\n",
      "424 - 29 nuclei identified\n",
      "425 - 28 nuclei identified\n",
      "426 - 24 nuclei identified\n",
      "427 - 24 nuclei identified\n",
      "428 - 27 nuclei identified\n",
      "429 - 26 nuclei identified\n",
      "430 - 29 nuclei identified\n",
      "431 - 30 nuclei identified\n",
      "432 - 30 nuclei identified\n",
      "433 - 23 nuclei identified\n",
      "434 - 21 nuclei identified\n",
      "435 - 29 nuclei identified\n",
      "436 - 26 nuclei identified\n",
      "437 - 27 nuclei identified\n",
      "438 - 21 nuclei identified\n",
      "439 - 27 nuclei identified\n",
      "440 - 25 nuclei identified\n",
      "441 - 27 nuclei identified\n",
      "442 - 27 nuclei identified\n",
      "443 - 28 nuclei identified\n",
      "444 - 26 nuclei identified\n",
      "445 - 30 nuclei identified\n",
      "446 - 27 nuclei identified\n"
     ]
    }
   ],
   "source": [
    "bs = 1.0 \n",
    "cs = 1.8\n",
    "ct = [9,22]\n",
    "hr = [10,16]\n",
    "hd = 10\n",
    "hp = 270\n",
    "ht = 0.12\n",
    "cr = 1.2\n",
    "\n",
    "out = np.zeros((images.shape[0], 512, 512, 3), dtype=np.uint8)\n",
    "pixx = []\n",
    "\n",
    "for i in range(3,images.shape[0]-3):\n",
    "#for i in range(3,10):\n",
    "  A00 = np.mean(images[i-3:i+4], axis=0)\n",
    "  A0 = A00 / np.amax(A00) # normalize\n",
    "  imageA = color.gray2rgb(np.uint8(255.0*A0))\n",
    "  imageB = color.gray2rgb(np.uint8(255.0*A00))\n",
    "\n",
    "  # identify nuclei (circles)   \n",
    "  #A = filters.gaussian(A0, sigma=gs) # noise filter\n",
    "  #A = denoise_wavelet(A0, wavelet_levels=7, multichannel=False, rescale_sigma=False)\n",
    "  A = denoise_bilateral(A0, sigma_spatial=bs)\n",
    "  Auint8 = np.uint8(255.0*A)\n",
    "  edges = canny(Auint8, sigma=cs, low_threshold=ct[0], high_threshold=ct[1])\n",
    "  hough_radii = np.arange(hr[0], hr[1], 1) # the range of radii to use in search\n",
    "  hough_res = hough_circle(edges, hough_radii) # look for circles\n",
    "  accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=hd, \n",
    "                                           min_ydistance=hd, total_num_peaks=hp, \n",
    "                                           threshold=ht, normalize=False)\n",
    "\n",
    "  # remove false positives (bright disks with dark perimeter)\n",
    "  pix = [] # as an empty list (for the remaining center pixels)\n",
    "  for center_y, center_x, radius in zip(cy, cx, radii):\n",
    "    c = circle(center_y, center_x, radius, shape=A0.shape) # central disk\n",
    "    cp = circle_perimeter(center_y, center_x, radius+1, shape=A0.shape) # perimeter ring\n",
    "    if (np.mean(imageA[cp]) / np.mean(imageA[c])) > cr:\n",
    "      pix.append((center_x, center_y)) # dark disks with bright perimeter are OK\n",
    "\n",
    "  # remove duplicates (close center pixels)\n",
    "  pix = np.array(pix) # as a numpy array\n",
    "  tree = cKDTree(pix) # for pairwise distance query\n",
    "  rows_to_fuse = list(tree.query_pairs(r=8.0))\n",
    "  p = np.ones(pix.shape[0])           # array of \"keep\" flags\n",
    "  p[np.array(rows_to_fuse)[:,0]] = 0  # flag the first of all duplicate pairs for deletion\n",
    "\n",
    "  temp = np.full((np.count_nonzero(p),1),np.float(i))\n",
    "  pp = pix[p.astype(bool)].astype(float)\n",
    "  pp = np.concatenate((pp,temp),axis=1)\n",
    "  pp = list(map(tuple,pp)) # the remaining center pixels \n",
    "\n",
    "  # draw nuclei centre pixels\n",
    "  for v in pp:\n",
    "    imageB[circle(v[1], v[0], 1.1, shape=A0.shape)] = (255,0,0)\n",
    "  out[i] = imageB\n",
    "\n",
    "  print(i, \"- \" + str(np.count_nonzero(p)) + \" nuclei identified\")\n",
    "  pixx += pp \n",
    "\n",
    "io.imsave(\"out.tif\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# save responses to CSV file\n",
    "t = []\n",
    "with open (\"pixx.csv\", 'w') as file:\n",
    "  writer = csv.writer(file)\n",
    "  for v in pixx:\n",
    "    writer.writerow('{:3.2e}'.format(x) for x in v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f33d4a6991643908dacd6179bcc759b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.close() # frees up memory\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "tp = np.array(pixx)\n",
    "ax.scatter(tp[:,0],tp[:,1],tp[:,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5a6424a770413aa11969ec53137cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 121\n",
      "Estimated number of noise points: 1007\n",
      "Clusters in first slice: 25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.close() # frees up memory\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "tp = np.array(pixx)\n",
    "tpp = tp * [1.0,1.0,0.5]\n",
    "db = DBSCAN(eps=10, min_samples=10).fit(tpp)\n",
    "labels = db.labels_\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    #if k == -1:\n",
    "        # Black used for noise.\n",
    "        #col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = tp[class_member_mask & core_samples_mask]\n",
    "    ax.scatter(xy[:, 0], xy[:, 1], xy[:, 2], color=tuple(col))\n",
    "\n",
    "    #xy = tp[class_member_mask & ~core_samples_mask]\n",
    "    #ax.scatter(xy[:, 0], xy[:, 1], xy[:, 2], color=tuple(col))\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n",
    "\n",
    "print(\"Clusters in first slice:\", np.count_nonzero((tp[labels!=-1]) == 3, axis=0)[2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30cca9d02864e1f9e72a0f41f5a1d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close() # frees up memory\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.set_xlim3d(0,512)\n",
    "ax.set_ylim3d(0,512)\n",
    "\n",
    "tpp = tp[labels==5]\n",
    "#print(tpp)\n",
    "ax.plot(tpp[:,0],tpp[:,1],tpp[:,2])\n",
    "\n",
    "#print(tpp)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf88696219214682b8566c8777b3f5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "x = tpp[:,0]\n",
    "y = tpp[:,1]\n",
    "z = tpp[:,2]\n",
    "\n",
    "tckp,u = splprep([x,y,z],s=2000,k=3,nest=-1)\n",
    "xnew,ynew,znew = splev(np.linspace(0,1,300),tckp)\n",
    "\n",
    "plt.close() # frees up memory\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.set_xlim3d(0,512)\n",
    "ax.set_ylim3d(0,512)\n",
    "\n",
    "ax.plot(xnew,ynew,znew)\n",
    "#ax.scatter(x,y,z,c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange, cos, linspace, pi, sin, random\n",
    "from scipy.interpolate import splprep, splev\n",
    "\n",
    "# make ascending spiral in 3-space\n",
    "t=linspace(0,1.75*2*pi,100)\n",
    "\n",
    "x = sin(t)\n",
    "y = cos(t)\n",
    "z = t\n",
    "\n",
    "# add noise\n",
    "x+= random.normal(scale=0.1, size=x.shape)\n",
    "y+= random.normal(scale=0.1, size=y.shape)\n",
    "z+= random.normal(scale=0.1, size=z.shape)\n",
    "\n",
    "# spline parameters\n",
    "s=3.0 # smoothness parameter\n",
    "k=2 # spline order\n",
    "nest=-1 # estimate of number of knots needed (-1 = maximal)\n",
    "\n",
    "# find the knot points\n",
    "tckp,u = splprep([x,y,z],s=s,k=k,nest=-1)\n",
    "\n",
    "# evaluate spline, including interpolated points\n",
    "xnew,ynew,znew = splev(linspace(0,1,400),tckp)\n",
    "\n",
    "import pylab\n",
    "pylab.subplot(2,2,1)\n",
    "data,=pylab.plot(x,y,'bo-',label='data')\n",
    "fit,=pylab.plot(xnew,ynew,'r-',label='fit')\n",
    "pylab.legend()\n",
    "pylab.xlabel('x')\n",
    "pylab.ylabel('y')\n",
    "\n",
    "pylab.subplot(2,2,2)\n",
    "data,=pylab.plot(x,z,'bo-',label='data')\n",
    "fit,=pylab.plot(xnew,znew,'r-',label='fit')\n",
    "pylab.legend()\n",
    "pylab.xlabel('x')\n",
    "pylab.ylabel('z')\n",
    "\n",
    "pylab.subplot(2,2,3)\n",
    "data,=pylab.plot(y,z,'bo-',label='data')\n",
    "fit,=pylab.plot(ynew,znew,'r-',label='fit')\n",
    "pylab.legend()\n",
    "pylab.xlabel('y')\n",
    "pylab.ylabel('z')\n",
    "\n",
    "pylab.savefig('splprep_demo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate sample data\n",
    "centers = [[1, 1], [-1, -1], [1, -1]]\n",
    "X, labels_true = make_blobs(n_samples=750, centers=centers, cluster_std=0.4,\n",
    "                            random_state=0)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# #############################################################################\n",
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels_true, labels))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels_true, labels))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels_true, labels))\n",
    "print(\"Adjusted Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))\n",
    "print(\"Adjusted Mutual Information: %0.3f\"\n",
    "      % metrics.adjusted_mutual_info_score(labels_true, labels))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, labels))\n",
    "\n",
    "# #############################################################################\n",
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/Borda/BIRL/blob/master/bm_experiments/bm_comp_perform.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from skimage import data, io\n",
    "from skimage.transform import resize, warp, AffineTransform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "from skimage.util import random_noise\n",
    "from skimage.restoration import denoise_bilateral, denoise_wavelet\n",
    "from skimage.feature import ORB, match_descriptors\n",
    "\n",
    "def register_image_pair(idx, path_img_target, path_img_source, path_out):\n",
    "    \"\"\" register two images together\n",
    "\n",
    "    :param int idx: empty parameter for using the function in parallel\n",
    "    :param str path_img_target: path to the target image\n",
    "    :param str path_img_source: path to the source image\n",
    "    :param str path_out: path for exporting the output\n",
    "    :return tuple(str,float):\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # load and denoise reference image\n",
    "    img_target = 10.0*io.imread(path_img_target)[0]\n",
    "    img_target = denoise_wavelet(img_target, wavelet_levels=7, multichannel=False, rescale_sigma=False)\n",
    "\n",
    "    # load and denoise moving image\n",
    "    img_source = 10.0*io.imread(path_img_source)[50]\n",
    "    img_source = denoise_bilateral(img_source, sigma_color=0.05,\n",
    "                                   sigma_spatial=2, multichannel=False)\n",
    "\n",
    "    # detect ORB features on both images\n",
    "    detector_target = ORB(n_keypoints=150)\n",
    "    detector_source = ORB(n_keypoints=150)\n",
    "    detector_target.detect_and_extract(img_target)\n",
    "    detector_source.detect_and_extract(img_source)\n",
    "    matches = match_descriptors(detector_target.descriptors,\n",
    "                                detector_source.descriptors)\n",
    "    print(matches)\n",
    "    \n",
    "    # robustly estimate affine transform model with RANSAC\n",
    "    model, inliers = ransac((detector_target.keypoints[matches[:, 0]],\n",
    "                       detector_source.keypoints[matches[:, 1]]),\n",
    "                      AffineTransform, min_samples=25, max_trials=500,\n",
    "                      residual_threshold=0.95)  # 0.95\n",
    "    print(inliers)\n",
    "    \n",
    "    # warping source image with estimated transformations\n",
    "    img_warped = warp(img_target, model.inverse, output_shape=img_target.shape[:2])\n",
    "    path_img_warped = os.path.join(path_out, \"result.tif\")\n",
    "    io.imsave(path_img_warped, img_warped)\n",
    "\n",
    "    # summarise experiment\n",
    "    execution_time = time.time() - start\n",
    "    return path_img_warped, execution_time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_image_pair(0, \n",
    "                    \"../image_stacks/Mistgcamp-3_0003.tif\", \n",
    "                    \"../image_stacks/Mistgcamp-3_0003.tif\", \n",
    "                    \"../image_stacks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transforms module uses a (x, y) coordinate convention to be consistent\n",
    "#with most of the warping literature out there.  But the rest of\n",
    "#scikit-image uses  a (row, column) convention.\n",
    "\n",
    "#The following code works for me:\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "image = io.imread('image.jpg')\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "xs = rng.randint(0, w - 1, 76)\n",
    "ys = rng.randint(0, h - 1, 76)\n",
    "\n",
    "src_pts = np.column_stack([xs, ys])\n",
    "dst_pts = src_pts\n",
    "\n",
    "tform = transform.PiecewiseAffineTransform()\n",
    "tform.estimate(src_pts, dst_pts)\n",
    "\n",
    "out = transform.warp(image, tform)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
