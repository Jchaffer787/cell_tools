{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python notebook for pre-processing apical image stack.\n",
    "# --- UNDER DEVELOPMENT ---\n",
    "Assumes folder directory structure:\n",
    "<pre><code>  IMAGING\n",
    "    image_stacks\n",
    "    notebooks\n",
    "    results\n",
    "</code></pre>\n",
    "Execute the code sequentially, one block at a time, using &lt;shift-return&gt;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.morphology import binary_erosion, binary_dilation\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "from skimage.transform import hough_circle, hough_circle_peaks, resize\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage import filters\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from ipyfilechooser import FileChooser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_stack = \"../image_stacks/Mistgcamp-3_0003.tif\"\n",
    "#image_stack = \"../image_stacks/MOVEMENT.tif\"\n",
    "#image_stack = \"../image_stacks/Movement2.tif\"\n",
    "#image_stack = \"../image_stacks/modestmovement.tif\"\n",
    "image_stack = \"../image_stacks/lessmovement3.tif\"\n",
    "image_bits = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up table for image plot color\n",
    "#   e.g. coolwarm, jet, plasma, gray\n",
    "lut = mpl.cm.gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load picture\n",
    "images = io.imread(image_stack)\n",
    "images = np.float32(images/(2.0**image_bits))\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "plt.imshow(images[0], norm=None, cmap=lut.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = np.sum(images[0:50], axis=0)/50.0\n",
    "for n in range(A0.shape[0] - 1): # moving average over every two lines\n",
    "  A0[n] = (A0[n] + A0[n+1]) / 2.0\n",
    "#A0 = exposure.equalize_hist(A0)\n",
    "A0 = filters.gaussian(A0, sigma=1.0)\n",
    "#fig=plt.figure(figsize=(10,10))\n",
    "#plt.imshow(A0, norm=None, cmap=lut.name)\n",
    "\n",
    "A0uint8 = np.uint8(255.0*A0)\n",
    "#fig=plt.figure(figsize=(10,10))\n",
    "#plt.imshow(A0uint8, norm=None, cmap=lut.name)\n",
    "\n",
    "edges = canny(A0uint8, sigma=2.0, low_threshold=0, high_threshold=0.1)\n",
    "#edges = binary_dilation(edges)\n",
    "#edges = binary_dilation(edges)\n",
    "#edges = binary_erosion(edges)\n",
    "#edges = remove_small_objects(edges, 5)\n",
    "#large = remove_small_objects(edges, 100)\n",
    "#edges = edges != large\n",
    "#fig=plt.figure(figsize=(10,10))\n",
    "#plt.imshow(edges, norm=None, cmap=lut.name)\n",
    "\n",
    "# Detect multiple radii\n",
    "hough_radii = np.arange(4, 8, 1)\n",
    "#print(hough_radii)\n",
    "hough_res = hough_circle(edges, hough_radii)\n",
    "#print(hough_res.shape)\n",
    "\n",
    "# Select the most prominent circles\n",
    "accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=10, \n",
    "                                           min_ydistance=10, total_num_peaks=300, \n",
    "                                           threshold=0.001, normalize=False)\n",
    "#print(radii)\n",
    "\n",
    "# Draw them\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10,10))\n",
    "imageA = color.gray2rgb(A0uint8)\n",
    "imageB = color.gray2rgb(edges)\n",
    "for center_y, center_x, radius in zip(cy, cx, radii):\n",
    "    #circy, circx = circle_perimeter(center_y, center_x, radius, shape=image.shape)\n",
    "    #imageA[circy, circx] = (255,0,0)\n",
    "    imageA[center_y, center_x] = (255,0,0)\n",
    "ax.imshow(imageA, norm=None)\n",
    "#ax[1].imshow(imageB, norm=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "@interact(\n",
    "  sr=widgets.IntRangeSlider(description='stack range',min=0, max=300, step=1, value=[0,10]), \n",
    "  gs=widgets.FloatSlider(description='GAUSSIAN sigma',min=0.0, max=4.0, step=0.1, value=1.0), \n",
    "  cs=widgets.FloatSlider(description='CANNY sigma',min=1.0, max=4.0, step=0.1, value=2.0), \n",
    "  ct=widgets.IntRangeSlider(description='threshold',min=0, max=100, step=1, value=[10,22]),\n",
    "  hr=widgets.IntRangeSlider(description='HOUGH radii',min=3, max=25, step=1, value=[5,8]),\n",
    "  hd=widgets.IntSlider(description='distance',min=5, max=20, step=1, value=10),\n",
    "  hp=widgets.IntSlider(description='peaks',min=50, max=500, step=10, value=260),\n",
    "  ht=widgets.FloatSlider(description='threshold',min=0.0, max=1.0, step=0.01, value=0.1))\n",
    "\n",
    "def f(sr, gs, cs, ct, hr, hd, hp, ht):\n",
    "  A0 = 1.8*np.sum(images[sr[0]:sr[1]], axis=0)/float(sr[1]-sr[0])\n",
    "  for n in range(A0.shape[0] - 1): # moving average over every two lines\n",
    "    A0[n] = (A0[n] + A0[n+1]) / 2.0\n",
    "  A = filters.gaussian(A0, sigma=gs)\n",
    "  Auint8 = np.uint8(255.0*A)\n",
    "  edges = canny(Auint8, sigma=cs, low_threshold=ct[0], high_threshold=ct[1])\n",
    "  hough_radii = np.arange(hr[0], hr[1], 1)\n",
    "  hough_res = hough_circle(edges, hough_radii)\n",
    "  accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii, min_xdistance=hd, \n",
    "                                           min_ydistance=hd, total_num_peaks=hp, \n",
    "                                           threshold=ht, normalize=False)\n",
    "  fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(10,10))\n",
    "  imageA = color.gray2rgb(np.uint8(255.0*A0))\n",
    "  imageB = color.gray2rgb(edges)\n",
    "  for center_y, center_x, radius in zip(cy, cx, radii):\n",
    "    imageA[center_y, center_x] = (255,0,0)\n",
    "  ax.imshow(imageA, norm=None)\n",
    "  plt.show()    \n",
    "  return()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://github.com/Borda/BIRL/blob/master/bm_experiments/bm_comp_perform.py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from skimage import data, io\n",
    "from skimage.transform import resize, warp, AffineTransform\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import ransac\n",
    "from skimage.util import random_noise\n",
    "from skimage.restoration import denoise_bilateral, denoise_wavelet\n",
    "from skimage.feature import ORB, match_descriptors\n",
    "\n",
    "def register_image_pair(idx, path_img_target, path_img_source, path_out):\n",
    "    \"\"\" register two images together\n",
    "\n",
    "    :param int idx: empty parameter for using the function in parallel\n",
    "    :param str path_img_target: path to the target image\n",
    "    :param str path_img_source: path to the source image\n",
    "    :param str path_out: path for exporting the output\n",
    "    :return tuple(str,float):\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # load and denoise reference image\n",
    "    img_target = 10.0*io.imread(path_img_target)[0]\n",
    "    img_target = denoise_wavelet(img_target, wavelet_levels=7, multichannel=False, rescale_sigma=False)\n",
    "\n",
    "    # load and denoise moving image\n",
    "    img_source = 10.0*io.imread(path_img_source)[50]\n",
    "    img_source = denoise_bilateral(img_source, sigma_color=0.05,\n",
    "                                   sigma_spatial=2, multichannel=False)\n",
    "\n",
    "    # detect ORB features on both images\n",
    "    detector_target = ORB(n_keypoints=150)\n",
    "    detector_source = ORB(n_keypoints=150)\n",
    "    detector_target.detect_and_extract(img_target)\n",
    "    detector_source.detect_and_extract(img_source)\n",
    "    matches = match_descriptors(detector_target.descriptors,\n",
    "                                detector_source.descriptors)\n",
    "    print(matches)\n",
    "    \n",
    "    # robustly estimate affine transform model with RANSAC\n",
    "    model, inliers = ransac((detector_target.keypoints[matches[:, 0]],\n",
    "                       detector_source.keypoints[matches[:, 1]]),\n",
    "                      AffineTransform, min_samples=25, max_trials=500,\n",
    "                      residual_threshold=0.95)  # 0.95\n",
    "    print(inliers)\n",
    "    \n",
    "    # warping source image with estimated transformations\n",
    "    img_warped = warp(img_target, model.inverse, output_shape=img_target.shape[:2])\n",
    "    path_img_warped = os.path.join(path_out, \"result.tif\")\n",
    "    io.imsave(path_img_warped, img_warped)\n",
    "\n",
    "    # summarise experiment\n",
    "    execution_time = time.time() - start\n",
    "    return path_img_warped, execution_time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   7]\n",
      " [  3  80]\n",
      " [  4 147]\n",
      " [ 11  86]\n",
      " [ 19  49]\n",
      " [ 21  23]\n",
      " [ 23  90]\n",
      " [ 24  53]\n",
      " [ 25 136]\n",
      " [ 28  30]\n",
      " [ 31  43]\n",
      " [ 36  68]\n",
      " [ 37 112]\n",
      " [ 41  70]\n",
      " [ 46  99]\n",
      " [ 47  79]\n",
      " [ 48 120]\n",
      " [ 50  56]\n",
      " [ 52 102]\n",
      " [ 61 105]\n",
      " [ 69  76]\n",
      " [ 72 137]\n",
      " [ 73  48]\n",
      " [ 79   9]\n",
      " [ 82 119]\n",
      " [ 83  78]\n",
      " [ 88 123]\n",
      " [ 91   0]\n",
      " [ 92   5]\n",
      " [ 95  52]\n",
      " [ 96 142]\n",
      " [ 97 126]\n",
      " [ 98 106]\n",
      " [102  91]\n",
      " [106  57]\n",
      " [107 131]\n",
      " [109  13]\n",
      " [110  93]\n",
      " [111  26]\n",
      " [112 115]\n",
      " [119  34]\n",
      " [120  25]\n",
      " [121  59]\n",
      " [124  64]\n",
      " [131  47]\n",
      " [132  95]\n",
      " [135  58]\n",
      " [140 100]\n",
      " [143  89]\n",
      " [146  28]\n",
      " [147  33]]\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../image_stacks/result.tif', 2.5475828647613525)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "register_image_pair(0, \n",
    "                    \"../image_stacks/Mistgcamp-3_0003.tif\", \n",
    "                    \"../image_stacks/Mistgcamp-3_0003.tif\", \n",
    "                    \"../image_stacks/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The transforms module uses a (x, y) coordinate convention to be consistent\n",
    "#with most of the warping literature out there.  But the rest of\n",
    "#scikit-image uses  a (row, column) convention.\n",
    "\n",
    "#The following code works for me:\n",
    "\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "image = io.imread('image.jpg')\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "xs = rng.randint(0, w - 1, 76)\n",
    "ys = rng.randint(0, h - 1, 76)\n",
    "\n",
    "src_pts = np.column_stack([xs, ys])\n",
    "dst_pts = src_pts\n",
    "\n",
    "tform = transform.PiecewiseAffineTransform()\n",
    "tform.estimate(src_pts, dst_pts)\n",
    "\n",
    "out = transform.warp(image, tform)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
